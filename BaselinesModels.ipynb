{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting utils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile utils.py\n",
    "import gzip\n",
    "import json\n",
    "\n",
    "def jl_to_list(filename):\n",
    "    output = []\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        for line in f:\n",
    "            output.append(json.loads(line))\n",
    "    return output\n",
    "\n",
    "def drop_duplicates(items):\n",
    "    seen = set()\n",
    "    seen_add = seen.add\n",
    "    return [x for x in items if not (x in seen or seen_add(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting models.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile models.py\n",
    "import math\n",
    "import random\n",
    "from collections import Counter, defaultdict\n",
    "from tqdm.notebook import tqdm\n",
    "from utils import drop_duplicates\n",
    "\n",
    "class AbstractBaseline(object):\n",
    "    def __init__(self, all_items, fill_model=None, k=10, verbose=True):\n",
    "        self.all_items = all_items\n",
    "        self.fill_model = fill_model\n",
    "        self.k = k\n",
    "        self.verbose = verbose\n",
    "    \n",
    "    def fit(self, X=None, y=None):\n",
    "        self._fit(X, y)\n",
    "        \n",
    "        if self.fill_model is not None:\n",
    "            self.fill_model.fit(X, y)\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def _fit(self, X, y):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X=None):\n",
    "        y_pred = []\n",
    "        \n",
    "        for row in (tqdm(X) if self.verbose else X):\n",
    "            recommendation = self._predict_one(row)\n",
    "            recommendation = self._fill_missing_values(row, recommendation)\n",
    "            y_pred.append(recommendation)\n",
    "        return y_pred\n",
    "    \n",
    "    def _predict_one(self, row):\n",
    "        pass\n",
    "    \n",
    "    def _fill_missing_values(self, row, recommendation):\n",
    "        recommendation = drop_duplicates(recommendation)[:10]\n",
    "        \n",
    "        missing_items = self.k - len(recommendation)\n",
    "        fill_items = []\n",
    "        if self.fill_model is None:\n",
    "            fill_items = random.choices(self.all_items, k=missing_items)\n",
    "        else:\n",
    "            fill_items = self.fill_model.predict([row])[0][:missing_items]\n",
    "        \n",
    "        return recommendation + fill_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to models.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a models.py\n",
    "\n",
    "class LastViewedBaseline(AbstractBaseline):\n",
    "    def __init__(self, all_items, fill_model=None, k=10, verbose=True):\n",
    "        super().__init__(all_items, fill_model=fill_model, k=k, verbose=verbose)\n",
    "    \n",
    "    def _predict_one(self, row):\n",
    "        viewed = [ev for ev in row['user_history'] if ev['event_type'] == 'view']\n",
    "        viewed = sorted(viewed, key=lambda x: x['event_timestamp'], reverse=True)\n",
    "        viewed = [ev['event_info'] for ev in viewed]\n",
    "\n",
    "        recommendation = []\n",
    "\n",
    "        for item in viewed:\n",
    "            if item not in recommendation:\n",
    "                recommendation.append(item)\n",
    "        \n",
    "        return recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to models.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a models.py\n",
    "\n",
    "class TopViewedItemsByMostFrequentDomainBaseline(AbstractBaseline):\n",
    "    def __init__(self, all_items, metadata, fill_model=None, k=10, max_views=30, verbose=True):\n",
    "        super().__init__(all_items, fill_model=fill_model, k=k, verbose=verbose)\n",
    "        self.max_views = max_views\n",
    "        self.metadata = metadata\n",
    "        self.viewed_items_by_domain = None\n",
    "    \n",
    "    def _fit(self, X=None, y=None):\n",
    "        self.viewed_items_by_domain = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "        for row in tqdm(X):\n",
    "            viewed = [ev['event_info'] for ev in row['user_history'] if ev['event_type'] == 'view']\n",
    "            for item in viewed:\n",
    "                domain = self.metadata[item]['domain_id']\n",
    "                self.viewed_items_by_domain[domain][item] += 1\n",
    "                \n",
    "        return self\n",
    "    \n",
    "    def _predict_one(self, row):\n",
    "        viewed = [ev['event_info'] for ev in row['user_history'] if ev['event_type'] == 'view']\n",
    "        if len(viewed) == 0:\n",
    "            return random.choices(self.all_items, k=self.k)\n",
    "        domain = self.__visited_domains(row)\n",
    "        domain = domain.most_common(1)[0][0]\n",
    "        return self.__top_items(domain)\n",
    "    \n",
    "    def __visited_domains(self, row):\n",
    "        domains = Counter()\n",
    "        viewed = [ev['event_info'] for ev in row['user_history'] if ev['event_type'] == 'view']\n",
    "        if len(viewed) > self.max_views:\n",
    "            viewed = viewed[:self.max_views]\n",
    "        for item in viewed:\n",
    "            domain = self.metadata[item]['domain_id']\n",
    "            domains[domain] += 1\n",
    "        return domains\n",
    "    \n",
    "    def __top_items(self, domain):\n",
    "        top = self.viewed_items_by_domain[domain]\n",
    "        top = Counter(top)\n",
    "        top = top.most_common(self.k)\n",
    "        recommendation = [x[0] for x in top]\n",
    "        \n",
    "        return recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting metrics.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile metrics.py\n",
    "import statistics\n",
    "import numpy as np\n",
    "from utils import drop_duplicates\n",
    "\n",
    "def ndcg(y_pred, y_true, metadata):\n",
    "    ndcg_values = []\n",
    "    \n",
    "    y_pred_cleaned = clean(y_pred)\n",
    "    \n",
    "    for i in range(len(y_pred_cleaned)):\n",
    "        dcg_value = dcg(y_pred_cleaned[i], y_true[i], metadata)\n",
    "        idcg_value = idcg(y_pred_cleaned[i], y_true[i])\n",
    "        ndcg_values.append(dcg_value / idcg_value)\n",
    "    \n",
    "    return statistics.mean(ndcg_values)\n",
    "\n",
    "def clean(y_pred):\n",
    "    results = []\n",
    "    \n",
    "    for items in y_pred:\n",
    "        items_clean = drop_duplicates(items)\n",
    "        missing_values = 10 - len(items_clean)\n",
    "        items_clean = items_clean + [0] * missing_values\n",
    "        results.append(items_clean)\n",
    "    \n",
    "    return results\n",
    "        \n",
    "def dcg(y_pred, y_true, metadata):\n",
    "    values = []\n",
    "    for i in range(len(y_pred)):\n",
    "        rel_value = rel(y_pred[i], y_true, metadata)\n",
    "        dcg_value = rel_value / np.log(i + 2.0)\n",
    "        values.append(dcg_value)\n",
    "    return np.sum(values)\n",
    "    \n",
    "def idcg(y_pred, y_true):\n",
    "    return 22.42461597\n",
    "\n",
    "def rel(y_hat, y, metadata):\n",
    "    if y_hat == y:\n",
    "        return 12.0\n",
    "    if domain(y_hat, metadata) == domain(y, metadata):\n",
    "        return 1.0\n",
    "    return 0.0\n",
    "\n",
    "def domain(item, metadata):\n",
    "    return metadata[item]['domain_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from utils import jl_to_list\n",
    "\n",
    "samples = 50000\n",
    "rows = jl_to_list('data/train_dataset.jl.gz')\n",
    "if samples:\n",
    "    rows = rows[:samples]\n",
    "rows_train, rows_test = train_test_split(rows, test_size=0.2, random_state=42)\n",
    "\n",
    "item_data = jl_to_list('data/item_data.jl.gz')\n",
    "\n",
    "metadata = {x['item_id']:x for x in item_data}\n",
    "all_items = list(metadata.keys())\n",
    "\n",
    "y_true = [row['item_bought'] for row in rows_test]\n",
    "\n",
    "test_dataset = jl_to_list('data/test_dataset.jl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c123edddaace4da6bbfc3009823917f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=40000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "437bb40de4f843a183712b92ef8fbdd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from models import TopViewedItemsByMostFrequentDomainBaseline, LastViewedBaseline\n",
    "\n",
    "fill_model = TopViewedItemsByMostFrequentDomainBaseline(all_items, metadata, verbose=False)\n",
    "baseline = LastViewedBaseline(all_items, fill_model=fill_model)\n",
    "baseline.fit(rows_train)\n",
    "y_pred = baseline.predict(rows_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2468331335418059"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from metrics import ndcg\n",
    "\n",
    "ndcg(y_pred, y_true, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = baseline.predict(test_dataset)\n",
    "df = pd.DataFrame(data=y_pred)\n",
    "df.to_csv(\"./results/fill_model.csv\",sep=',',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "651761a5aaa1499fa207e9e655b2bc37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=40000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faa002f147884c2abe7c8f5f3a2630c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "baseline = TopViewedItemsByMostFrequentDomainBaseline(all_items, metadata)\n",
    "baseline.fit(rows_train)\n",
    "y_pred = baseline.predict(rows_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1398981169433177"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndcg(y_pred, y_true, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=y_pred)\n",
    "df[df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
